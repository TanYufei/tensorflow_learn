{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# /usr/bin/python\n",
    "# -*- encoding:utf-8 -*-\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# 1、xgBoost的基本使用\n",
    "# 2、自定义损失函数的梯度和二阶导\n",
    "# 3、binary:logistic/logitraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义f: theta * x\n",
    "def log_reg(y_hat, y):\n",
    "    p = 1.0 / (1.0 + np.exp(-y_hat))\n",
    "    g = p - y.get_label()\n",
    "    h = p * (1.0-p)\n",
    "    return g, h\n",
    "\n",
    "\n",
    "def error_rate(y_hat, y):\n",
    "    return 'error', float(sum(y.get_label() != (y_hat > 0.5))) / len(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xgboost.core.DMatrix object at 0x7f3aa277d310>\n",
      "<class 'xgboost.core.DMatrix'>\n",
      "[0]\teval-error:0.016139\ttrain-error:0.014433\n",
      "[1]\teval-error:0.016139\ttrain-error:0.014433\n",
      "[2]\teval-error:0.016139\ttrain-error:0.014433\n",
      "[3]\teval-error:0.016139\ttrain-error:0.014433\n",
      "[4]\teval-error:0.002483\ttrain-error:0.003071\n",
      "[5]\teval-error:0.002483\ttrain-error:0.003071\n",
      "[6]\teval-error:0.002483\ttrain-error:0.003071\n",
      "[  6.09937888e-06   9.84727502e-01   6.09937888e-06 ...,   9.99932647e-01\n",
      "   4.45600620e-07   9.99932647e-01]\n",
      "[ 0.  1.  0. ...,  1.  0.  1.]\n",
      "样本总数：\t1611\n",
      "错误数目：\t   4\n",
      "错误率：\t0.24829%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 读取数据\n",
    "    data_train = xgb.DMatrix('agaricus_train.txt')\n",
    "    data_test = xgb.DMatrix('agaricus_test.txt')\n",
    "    print data_train\n",
    "    print type(data_train)\n",
    "\n",
    "    # 设置参数\n",
    "    param = {'max_depth': 3, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'} # logitraw\n",
    "    # param = {'max_depth': 3, 'eta': 0.3, 'silent': 1, 'objective': 'reg:logistic'}\n",
    "    watchlist = [(data_test, 'eval'), (data_train, 'train')]\n",
    "    n_round = 7\n",
    "    # bst = xgb.train(param, data_train, num_boost_round=n_round, evals=watchlist)\n",
    "    bst = xgb.train(param, data_train, num_boost_round=n_round, evals=watchlist, obj=log_reg, feval=error_rate)\n",
    "\n",
    "    # 计算错误率\n",
    "    y_hat = bst.predict(data_test)\n",
    "    y = data_test.get_label()\n",
    "    print y_hat\n",
    "    print y\n",
    "    error = sum(y != (y_hat > 0.5))\n",
    "    error_rate = float(error) / len(y_hat)\n",
    "    print '样本总数：\\t', len(y_hat)\n",
    "    print '错误数目：\\t%4d' % error\n",
    "    print '错误率：\\t%.5f%%' % (100*error_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
